{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb047ee",
   "metadata": {},
   "source": [
    "## Модуль В. Обработка и анализ текстовых данных (инвариант)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f5e819",
   "metadata": {},
   "source": [
    "#### Сформировать структуру набора данных.  Провести предварительную обработку данных. Произвести кластеризацию и дать описание кластерам. Произвести классификацию на основе: результатов кластеризации или в соответствии с бизнес-задачей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e0cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d73a8c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return ''.join([i for i in text if i not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aed0d657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_num(text):\n",
    "    return ''.join([i if not i.isdigit() else '' for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37916da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    txt = word_tokenize(text)\n",
    "    tokenize_text = ''.join([i for i in txt if i not in all_stopword])\n",
    "    return tokenize_text\n",
    "\n",
    "df['token'] = df['token'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837fcfd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bc916e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "902756a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import pymorphy2\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "971d54c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMDB-Dataset.csv')\n",
    "df = df.iloc[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d7878e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e1d12ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     10000 non-null  object\n",
      " 1   sentiment  10000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 156.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2bfa62df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Fun, entertaining movie about WWII German spy ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Give me a break. How can anyone say that this ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>This movie is a bad movie. But after watching ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>This is a movie that was probably made to ente...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Smashing film about film-making. Shows the int...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review sentiment\n",
       "0     One of the other reviewers has mentioned that ...  positive\n",
       "1     A wonderful little production. <br /><br />The...  positive\n",
       "2     I thought this was a wonderful way to spend ti...  positive\n",
       "3     Basically there's a family where a little boy ...  negative\n",
       "4     Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                 ...       ...\n",
       "9995  Fun, entertaining movie about WWII German spy ...  positive\n",
       "9996  Give me a break. How can anyone say that this ...  negative\n",
       "9997  This movie is a bad movie. But after watching ...  negative\n",
       "9998  This is a movie that was probably made to ente...  negative\n",
       "9999  Smashing film about film-making. Shows the int...  positive\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca938868",
   "metadata": {},
   "source": [
    "Перевод строковых данных в нижний регистр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c805a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].str.lower()\n",
    "df['sentiment'] = df['sentiment'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3906e62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['rating'] = df['rating'].fillna(0)\n",
    "# df['city'] = df['city'].fillna('Не указано')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d01150d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.to_excel('nlp_justpractic_1.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d857f8c3",
   "metadata": {},
   "source": [
    "Переименовали названия столбцов для удобства"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01de3e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'review': 'текст_отзыва', 'sentiment': 'тон'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e75b8699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>текст_отзыва</th>\n",
       "      <th>тон</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>fun, entertaining movie about wwii german spy ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>give me a break. how can anyone say that this ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>this movie is a bad movie. but after watching ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>this is a movie that was probably made to ente...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>smashing film about film-making. shows the int...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           текст_отзыва       тон\n",
       "0     one of the other reviewers has mentioned that ...  positive\n",
       "1     a wonderful little production. <br /><br />the...  positive\n",
       "2     i thought this was a wonderful way to spend ti...  positive\n",
       "3     basically there's a family where a little boy ...  negative\n",
       "4     petter mattei's \"love in the time of money\" is...  positive\n",
       "...                                                 ...       ...\n",
       "9995  fun, entertaining movie about wwii german spy ...  positive\n",
       "9996  give me a break. how can anyone say that this ...  negative\n",
       "9997  this movie is a bad movie. but after watching ...  negative\n",
       "9998  this is a movie that was probably made to ente...  negative\n",
       "9999  smashing film about film-making. shows the int...  positive\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f4b67081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "текст_отзыва    0\n",
       "тон             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e81002f",
   "metadata": {},
   "source": [
    "## Обработка естественного языка.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "927cb287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae541853",
   "metadata": {},
   "source": [
    "Удаление пунктуации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "30fd0f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuaction(text):\n",
    "    return ''.join([i for i in text if i not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bbd20031",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prep_text'] = [remove_punctuation(text.lower()) for text in df['текст_отзыва']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ec49ec",
   "metadata": {},
   "source": [
    "Очистка от специальных символов и лишних пробелов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a1be380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(text): \n",
    "    return ''.join([i if not i.isdigit() else ' ' for i in text])\n",
    "\n",
    "def remove_multiple_spaces(text): \n",
    "    return re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "\n",
    "st = '><\\xa0—«»/&%^()$#@!~№;:?*_-+=|.,)\"\"'\n",
    "def remove_othersymbol(text):\n",
    "    return ''.join([ch if ch not in st else ' ' for ch in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5357a2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prep_text'] = [remove_numbers(text.lower()) for text in df['prep_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "046ff202",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prep_text'] = [remove_othersymbol(text.lower()) for text in df['prep_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddca2d9",
   "metadata": {},
   "source": [
    "Удаление стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a1a1a280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Регина\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Error loading word_tokenize: Package 'word_tokenize' not\n",
      "[nltk_data]     found in index\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Регина\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('word_tokenize')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f08b5499",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_ru = stopwords.words('russian')\n",
    "stopword_eng = stopwords.words('english')\n",
    "\n",
    "all_stopword = stopword_ru + stopword_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bc371f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stopword.append(\"br\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b553091f",
   "metadata": {},
   "source": [
    "Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b68aa318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сегментация, разделение предлож на слова компоненты\n",
    "def tokenize(text):\n",
    "    t = word_tokenize(text)\n",
    "    tokens = [token for token in t if token not in all_stopword]\n",
    "    tokenize_text = ' '.join(tokens)\n",
    "    return tokenize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e18934bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_tokenize'] = [tokenize(text.lower()) for text in df['prep_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f62e26",
   "metadata": {},
   "source": [
    "Лемматизация (приводим к именительному падежу и ед числу)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6c950a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import MorphVocab, Doc, Segmenter\n",
    "\n",
    "morph_vocab = MorphVocab()\n",
    "\n",
    "def lemmatize(word_list):\n",
    "    doc = Doc(word_list)\n",
    "    segmenter = Segmenter()\n",
    "    doc.segment(segmenter)\n",
    "    lemmatized_text = ' '.join([morph_vocab.parse(token.text)[0].normal for token in doc.tokens])\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bf11bb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemm'] = df['text_tokenize'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b3cb7ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>текст_отзыва</th>\n",
       "      <th>тон</th>\n",
       "      <th>prep_text</th>\n",
       "      <th>text_tokenize</th>\n",
       "      <th>lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>one reviewers mentioned watching oz episode yo...</td>\n",
       "      <td>one reviewers mentioned watching oz episode yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "      <td>a wonderful little production br br the filmin...</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>basically theres a family where a little boy j...</td>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>petter matteis love in the time of money is a ...</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>fun, entertaining movie about wwii german spy ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>fun entertaining movie about wwii german spy j...</td>\n",
       "      <td>fun entertaining movie wwii german spy julie a...</td>\n",
       "      <td>fun entertaining movie wwii german spy julie a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>give me a break. how can anyone say that this ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>give me a break how can anyone say that this i...</td>\n",
       "      <td>give break anyone say good hockey movie know m...</td>\n",
       "      <td>give break anyone say good hockey movie know m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>this movie is a bad movie. but after watching ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>this movie is a bad movie but after watching a...</td>\n",
       "      <td>movie bad movie watching endless series bad ho...</td>\n",
       "      <td>movie bad movie watching endless series bad ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>this is a movie that was probably made to ente...</td>\n",
       "      <td>negative</td>\n",
       "      <td>this is a movie that was probably made to ente...</td>\n",
       "      <td>movie probably made entertain middle school ea...</td>\n",
       "      <td>movie probably made entertain middle school ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>smashing film about film-making. shows the int...</td>\n",
       "      <td>positive</td>\n",
       "      <td>smashing film about filmmaking shows the inten...</td>\n",
       "      <td>smashing film filmmaking shows intense strange...</td>\n",
       "      <td>smashing film filmmaking shows intense strange...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           текст_отзыва       тон  \\\n",
       "0     one of the other reviewers has mentioned that ...  positive   \n",
       "1     a wonderful little production. <br /><br />the...  positive   \n",
       "2     i thought this was a wonderful way to spend ti...  positive   \n",
       "3     basically there's a family where a little boy ...  negative   \n",
       "4     petter mattei's \"love in the time of money\" is...  positive   \n",
       "...                                                 ...       ...   \n",
       "9995  fun, entertaining movie about wwii german spy ...  positive   \n",
       "9996  give me a break. how can anyone say that this ...  negative   \n",
       "9997  this movie is a bad movie. but after watching ...  negative   \n",
       "9998  this is a movie that was probably made to ente...  negative   \n",
       "9999  smashing film about film-making. shows the int...  positive   \n",
       "\n",
       "                                              prep_text  \\\n",
       "0     one of the other reviewers has mentioned that ...   \n",
       "1     a wonderful little production br br the filmin...   \n",
       "2     i thought this was a wonderful way to spend ti...   \n",
       "3     basically theres a family where a little boy j...   \n",
       "4     petter matteis love in the time of money is a ...   \n",
       "...                                                 ...   \n",
       "9995  fun entertaining movie about wwii german spy j...   \n",
       "9996  give me a break how can anyone say that this i...   \n",
       "9997  this movie is a bad movie but after watching a...   \n",
       "9998  this is a movie that was probably made to ente...   \n",
       "9999  smashing film about filmmaking shows the inten...   \n",
       "\n",
       "                                          text_tokenize  \\\n",
       "0     one reviewers mentioned watching oz episode yo...   \n",
       "1     wonderful little production filming technique ...   \n",
       "2     thought wonderful way spend time hot summer we...   \n",
       "3     basically theres family little boy jake thinks...   \n",
       "4     petter matteis love time money visually stunni...   \n",
       "...                                                 ...   \n",
       "9995  fun entertaining movie wwii german spy julie a...   \n",
       "9996  give break anyone say good hockey movie know m...   \n",
       "9997  movie bad movie watching endless series bad ho...   \n",
       "9998  movie probably made entertain middle school ea...   \n",
       "9999  smashing film filmmaking shows intense strange...   \n",
       "\n",
       "                                                   lemm  \n",
       "0     one reviewers mentioned watching oz episode yo...  \n",
       "1     wonderful little production filming technique ...  \n",
       "2     thought wonderful way spend time hot summer we...  \n",
       "3     basically theres family little boy jake thinks...  \n",
       "4     petter matteis love time money visually stunni...  \n",
       "...                                                 ...  \n",
       "9995  fun entertaining movie wwii german spy julie a...  \n",
       "9996  give break anyone say good hockey movie know m...  \n",
       "9997  movie bad movie watching endless series bad ho...  \n",
       "9998  movie probably made entertain middle school ea...  \n",
       "9999  smashing film filmmaking shows intense strange...  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcfe489",
   "metadata": {},
   "source": [
    "Векторизация текстовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "42067b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключение библиотек.\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bc12212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word', stop_words=stopword_eng, ngram_range=(1, 3), min_df=2)\n",
    "count_matrix = vectorizer.fit_transform(df['lemm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "42f3c02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 158618)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c93c6ac",
   "metadata": {},
   "source": [
    "Количество строк в count_matrix не соотвествует количеству строк в df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fd3d9dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aag', 'aaliyah', 'aaliyahs', ..., 'élan', 'élan unique',\n",
       "       'élan unique personal'], dtype=object)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e7d033",
   "metadata": {},
   "source": [
    "## Кластеризация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cf506521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключение библиотек.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5a07df",
   "metadata": {},
   "source": [
    "Для лучшего нахождения кластеров выполним скалирование данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2285ce52",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 11.8 GiB for an array with shape (10000, 158618) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Создание DataFrame с данными tfidf_matrix.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mget_feature_names_out()\n\u001b[1;32m----> 3\u001b[0m tfidf_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(count_matrix\u001b[38;5;241m.\u001b[39mtoarray(), columns\u001b[38;5;241m=\u001b[39mfeature_names)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Скалирование данных.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler(with_mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:1050\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1049\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1050\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_toarray_args(order, out)\n\u001b[0;32m   1051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_base.py:1267\u001b[0m, in \u001b[0;36m_spbase._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 11.8 GiB for an array with shape (10000, 158618) and data type int64"
     ]
    }
   ],
   "source": [
    "# Создание DataFrame с данными tfidf_matrix.\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "tfidf_df = pd.DataFrame(count_matrix.toarray(), columns=feature_names)\n",
    "\n",
    "# Скалирование данных.\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "scaler.fit(df)\n",
    "X_scale = scaler.transform(df)\n",
    "scaled_data = pd.DataFrame(X_scale, columns=df.columns)\n",
    "\n",
    "# Уменьшение размерности DataFrame до 2-х измерений\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(scaled_data)\n",
    "\n",
    "x_pca = pca.transform(scaled_data)\n",
    "np.shape(x_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1377a5f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m11\u001b[39m):\n\u001b[0;32m      3\u001b[0m     kmean \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39mi, init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk-means++\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     kmean\u001b[38;5;241m.\u001b[39mfit(x_pca)\n\u001b[0;32m      5\u001b[0m     wgcc\u001b[38;5;241m.\u001b[39mappend(kmean\u001b[38;5;241m.\u001b[39minertia_)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m11\u001b[39m), wgcc)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_pca' is not defined"
     ]
    }
   ],
   "source": [
    "wgcc = []\n",
    "for i in range(1,11):\n",
    "    kmean = KMeans(n_clusters=i, init='k-means++', random_state=0)\n",
    "    kmean.fit(x_pca)\n",
    "    wgcc.append(kmean.inertia_)\n",
    "plt.plot(range(1,11), wgcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9d869e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 1, 1, 2])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit_predict(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bdd9ce20",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kmeans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics\n\u001b[1;32m----> 3\u001b[0m kmeans\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num_clusters \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m      6\u001b[0m     kmeans \u001b[38;5;241m=\u001b[39m KMeans(init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk-means++\u001b[39m\u001b[38;5;124m'\u001b[39m, n_clusters\u001b[38;5;241m=\u001b[39mnum_clusters, n_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'kmeans' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "kmeans.fit(X)\n",
    "for num_clusters in np.arange(2, 10):\n",
    "\n",
    "    kmeans = KMeans(init='k-means++', n_clusters=num_clusters, n_init=10)\n",
    "    kmeans.fit(X)\n",
    "    score = metrics.silhouette_score(X, kmeans.labels_, \n",
    "                metric='euclidean', sample_size=len(X))\n",
    "\n",
    "    print(\"\\nNumber of clusters =\", num_clusters)\n",
    "    print(\"Silhouette score =\", score)\n",
    "                    \n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a39405b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = kmeans.fit_predict(tfidf_matrix)\n",
    "clusters_kmeans = kmeans.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "138c8a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = { 'skills': df['тон'], 'cluster': clusters_kmeans }\n",
    "frame_kmeans = pd.DataFrame(out, columns = ['skills', 'cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ecaa648b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "0    4477\n",
       "1    2924\n",
       "2    2599\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_kmeans['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53aa217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код для нахождения 10 распространенных слов для каждого кластера, чтобы потом дать им названия.\n",
    "\n",
    "top_words = 10\n",
    "cluster_centers_kmeans = kmeans.cluster_centers_\n",
    "cluster_keywords_kmeans = {}\n",
    "\n",
    "for i in range(len(cluster_centers_kmeans)):\n",
    "    top_words_idx = cluster_centers_kmeans[i].argsort()[:-top_words-1:-1]\n",
    "    keywords = [feature_names[idx] for idx in top_words_idx]\n",
    "    cluster_keywords_kmeans[f'Кластер {i}'] = keywords\n",
    "\n",
    "for cluster, keywords in cluster_keywords_kmeans.items():\n",
    "    print(f'{cluster}: {\", \".join(keywords)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2443907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исходная TF-IDF матрица.\n",
    "kmeans_clusters = kmeans.fit_predict(tfidf_matrix)\n",
    "kmeans_score = silhouette_score(tfidf_matrix, kmeans_clusters)\n",
    "print(f'Силуэт для Kmeans: {kmeans_score}')\n",
    "\n",
    "print()\n",
    "\n",
    "# TF-IDF матрица, в которой было произведено скалирование данных и уменьшение размерности до 2-х измерений.\n",
    "kmeans_ = KMeans(n_clusters=5)\n",
    "kmeans_clusters_ = kmeans.fit_predict(x_pca)\n",
    "kmeans_score_ = silhouette_score(x_pca, kmeans_clusters_)\n",
    "print(f'Силуэт для Kmeans: {kmeans_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2f42cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster'] = clusters_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c26e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b8a2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078fdaff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf05f0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prep_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af52f1df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ebc7d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9703d703",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
